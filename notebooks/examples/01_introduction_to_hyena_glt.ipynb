{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5c6965b",
   "metadata": {},
   "source": [
    "# Introduction to Hyena-GLT: Genomic Language Transformer\n",
    "\n",
    "Welcome to Hyena-GLT! This notebook provides a comprehensive introduction to the framework that combines BLT's byte latent tokenization with Savanna's Striped Hyena blocks for efficient genomic sequence modeling.\n",
    "\n",
    "## 🎯 Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will:\n",
    "- Understand the Hyena-GLT architecture\n",
    "- Learn how to process genomic data\n",
    "- Train your first genomic model\n",
    "- Evaluate model performance\n",
    "- Apply the model to real genomic tasks\n",
    "\n",
    "## 📋 Prerequisites\n",
    "\n",
    "- Basic Python knowledge\n",
    "- Understanding of genomic sequences (DNA/RNA/protein)\n",
    "- Familiarity with machine learning concepts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b52745de",
   "metadata": {},
   "source": [
    "## 1. Installation and Setup\n",
    "\n",
    "First, let's install and import the necessary packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861599d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages (uncomment if needed)\n",
    "# !pip install torch transformers numpy pandas matplotlib seaborn\n",
    "# !pip install biopython scikit-learn plotly\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the project root to Python path\n",
    "project_root = os.path.abspath('../..')\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n",
    "# Core imports\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Hyena-GLT imports\n",
    "from hyena_glt.config import HyenaGLTConfig\n",
    "from hyena_glt.data import (\n",
    "    DNATokenizer, RNATokenizer, ProteinTokenizer,\n",
    "    GenomicDataset, GenomicUtilities\n",
    ")\n",
    "from hyena_glt.model import HyenaGLT\n",
    "from hyena_glt.training import HyenaGLTTrainer, TrainingConfig\n",
    "from hyena_glt.evaluation import GenomicMetrics, ModelAnalyzer\n",
    "\n",
    "# Set up plotting\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"🧬 Hyena-GLT setup complete!\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"Device: {'CUDA' if torch.cuda.is_available() else 'CPU'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fca96e4",
   "metadata": {},
   "source": [
    "## 2. Understanding Genomic Data\n",
    "\n",
    "Let's start by exploring different types of genomic sequences and how Hyena-GLT processes them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eebf296c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample genomic sequences\n",
    "dna_sequence = \"ATCGATCGTAGCTAGCTAGCGATCGATCGTAGCTAGC\"\n",
    "rna_sequence = \"AUCGAUCGUAGCUAGCUAGCGAUCGAUCGUAGCUAGC\"\n",
    "protein_sequence = \"MKTVRQERLKSIVRILKESSKGRPPPQDVTAKRAEQFVDQAQIILEQPKQRGFRFR\"\n",
    "\n",
    "print(\"Sample Sequences:\")\n",
    "print(f\"DNA:     {dna_sequence}\")\n",
    "print(f\"RNA:     {rna_sequence}\")\n",
    "print(f\"Protein: {protein_sequence}\")\n",
    "\n",
    "# Initialize tokenizers\n",
    "dna_tokenizer = DNATokenizer()\n",
    "rna_tokenizer = RNATokenizer()\n",
    "protein_tokenizer = ProteinTokenizer()\n",
    "\n",
    "print(\"\\nTokenizer Vocabularies:\")\n",
    "print(f\"DNA vocab size:     {dna_tokenizer.vocab_size}\")\n",
    "print(f\"RNA vocab size:     {rna_tokenizer.vocab_size}\")\n",
    "print(f\"Protein vocab size: {protein_tokenizer.vocab_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b482fdd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize sequences\n",
    "dna_tokens = dna_tokenizer.encode(dna_sequence)\n",
    "rna_tokens = rna_tokenizer.encode(rna_sequence)\n",
    "protein_tokens = protein_tokenizer.encode(protein_sequence)\n",
    "\n",
    "print(\"Tokenized Sequences:\")\n",
    "print(f\"DNA tokens:     {dna_tokens[:10]}... (length: {len(dna_tokens)})\")\n",
    "print(f\"RNA tokens:     {rna_tokens[:10]}... (length: {len(rna_tokens)})\")\n",
    "print(f\"Protein tokens: {protein_tokens[:10]}... (length: {len(protein_tokens)})\")\n",
    "\n",
    "# Demonstrate decoding\n",
    "decoded_dna = dna_tokenizer.decode(dna_tokens)\n",
    "print(f\"\\nDecoded DNA: {decoded_dna}\")\n",
    "print(f\"Original DNA: {dna_sequence}\")\n",
    "print(f\"Match: {decoded_dna == dna_sequence}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03e1034",
   "metadata": {},
   "source": [
    "## 3. Model Configuration\n",
    "\n",
    "Hyena-GLT uses a comprehensive configuration system. Let's explore different configurations for various genomic tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b8bd3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create configurations for different tasks\n",
    "configs = {}\n",
    "\n",
    "# DNA sequence classification\n",
    "configs['dna_classification'] = HyenaGLTConfig.for_dna_classification(\n",
    "    num_classes=5,  # e.g., promoter, enhancer, intron, exon, intergenic\n",
    "    max_length=1024,\n",
    "    hidden_size=256,\n",
    "    num_layers=6\n",
    ")\n",
    "\n",
    "# Protein function prediction\n",
    "configs['protein_function'] = HyenaGLTConfig.for_protein_function(\n",
    "    num_functions=100,  # number of GO terms\n",
    "    max_length=512,\n",
    "    hidden_size=384,\n",
    "    num_layers=8\n",
    ")\n",
    "\n",
    "# RNA secondary structure\n",
    "configs['rna_structure'] = HyenaGLTConfig.for_rna_structure(\n",
    "    max_length=256,\n",
    "    hidden_size=256,\n",
    "    num_layers=6\n",
    ")\n",
    "\n",
    "# Display configuration details\n",
    "for task, config in configs.items():\n",
    "    print(f\"\\n{task.upper()} Configuration:\")\n",
    "    print(f\"  Sequence type: {config.sequence_type}\")\n",
    "    print(f\"  Task type: {config.task_type}\")\n",
    "    print(f\"  Max length: {config.max_length}\")\n",
    "    print(f\"  Hidden size: {config.hidden_size}\")\n",
    "    print(f\"  Layers: {config.num_layers}\")\n",
    "    print(f\"  Hyena order: {config.hyena_order}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17fbef8",
   "metadata": {},
   "source": [
    "## 4. Model Architecture Overview\n",
    "\n",
    "Let's create and examine the Hyena-GLT model architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21084194",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a model for DNA classification\n",
    "config = configs['dna_classification']\n",
    "model = HyenaGLT(config)\n",
    "\n",
    "# Model summary\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "total_params = count_parameters(model)\n",
    "print(f\"Model Parameters: {total_params:,}\")\n",
    "\n",
    "# Model architecture breakdown\n",
    "print(\"\\nModel Components:\")\n",
    "for name, module in model.named_children():\n",
    "    params = sum(p.numel() for p in module.parameters())\n",
    "    print(f\"  {name}: {params:,} parameters\")\n",
    "\n",
    "# Test forward pass\n",
    "batch_size = 4\n",
    "seq_length = 128\n",
    "sample_input = torch.randint(0, config.vocab_size, (batch_size, seq_length))\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = model(sample_input)\n",
    "    \n",
    "print(f\"\\nSample Forward Pass:\")\n",
    "print(f\"Input shape: {sample_input.shape}\")\n",
    "print(f\"Output shape: {output.logits.shape}\")\n",
    "print(f\"Hidden states shape: {output.hidden_states.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ff5eb2",
   "metadata": {},
   "source": [
    "## 5. Data Preparation\n",
    "\n",
    "Let's create synthetic genomic data for demonstration and learn how to prepare datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37588a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic genomic data\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "def generate_synthetic_data(n_samples=1000, seq_length=256):\n",
    "    \"\"\"Generate synthetic DNA sequences with labels.\"\"\"\n",
    "    # DNA alphabet\n",
    "    bases = ['A', 'T', 'C', 'G']\n",
    "    \n",
    "    sequences = []\n",
    "    labels = []\n",
    "    \n",
    "    for i in range(n_samples):\n",
    "        # Generate random sequence\n",
    "        seq = ''.join(np.random.choice(bases, seq_length))\n",
    "        \n",
    "        # Simple labeling rules (for demonstration)\n",
    "        gc_content = (seq.count('G') + seq.count('C')) / len(seq)\n",
    "        \n",
    "        if gc_content < 0.3:\n",
    "            label = 0  # AT-rich (e.g., intergenic)\n",
    "        elif gc_content < 0.5:\n",
    "            label = 1  # Moderate GC (e.g., intron)\n",
    "        elif gc_content < 0.7:\n",
    "            label = 2  # GC-rich (e.g., exon)\n",
    "        else:\n",
    "            label = 3  # Very GC-rich (e.g., promoter)\n",
    "            \n",
    "        # Add some pattern-based labels\n",
    "        if 'TATAAA' in seq:  # TATA box motif\n",
    "            label = 4  # Promoter\n",
    "            \n",
    "        sequences.append(seq)\n",
    "        labels.append(label)\n",
    "    \n",
    "    return sequences, labels\n",
    "\n",
    "# Generate data\n",
    "sequences, labels = generate_synthetic_data(1000, 256)\n",
    "\n",
    "# Create dataset\n",
    "tokenizer = DNATokenizer()\n",
    "dataset = GenomicDataset(\n",
    "    sequences=sequences,\n",
    "    labels=labels,\n",
    "    tokenizer=tokenizer,\n",
    "    max_length=config.max_length\n",
    ")\n",
    "\n",
    "print(f\"Dataset size: {len(dataset)}\")\n",
    "print(f\"Label distribution:\")\n",
    "label_counts = pd.Series(labels).value_counts().sort_index()\n",
    "for label, count in label_counts.items():\n",
    "    print(f\"  Class {label}: {count} samples\")\n",
    "\n",
    "# Examine a sample\n",
    "sample = dataset[0]\n",
    "print(f\"\\nSample data structure:\")\n",
    "print(f\"  Input IDs shape: {sample['input_ids'].shape}\")\n",
    "print(f\"  Attention mask shape: {sample['attention_mask'].shape}\")\n",
    "print(f\"  Label: {sample['labels']}\")\n",
    "\n",
    "# Visualize GC content distribution\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "gc_contents = [(seq.count('G') + seq.count('C')) / len(seq) for seq in sequences]\n",
    "plt.hist(gc_contents, bins=30, alpha=0.7, color='skyblue')\n",
    "plt.xlabel('GC Content')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of GC Content')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "label_names = ['AT-rich', 'Moderate GC', 'GC-rich', 'Very GC-rich', 'TATA-box']\n",
    "plt.bar(range(len(label_counts)), label_counts.values, color='lightcoral')\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Class Distribution')\n",
    "plt.xticks(range(len(label_names)), label_names, rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e540d41c",
   "metadata": {},
   "source": [
    "## 6. Training Your First Model\n",
    "\n",
    "Now let's train a Hyena-GLT model on our synthetic genomic data. We'll use a simple training setup to get started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7695354",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "# Split dataset\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "print(f\"Training samples: {len(train_dataset)}\")\n",
    "print(f\"Validation samples: {len(val_dataset)}\")\n",
    "\n",
    "# Configure training\n",
    "training_config = TrainingConfig(\n",
    "    num_epochs=10,\n",
    "    learning_rate=1e-4,\n",
    "    warmup_steps=100,\n",
    "    weight_decay=0.01,\n",
    "    gradient_clip_norm=1.0,\n",
    "    save_steps=200,\n",
    "    eval_steps=200,\n",
    "    logging_steps=50\n",
    ")\n",
    "\n",
    "# Initialize trainer\n",
    "trainer = HyenaGLTTrainer(\n",
    "    model=model,\n",
    "    config=training_config,\n",
    "    train_loader=train_loader,\n",
    "    eval_loader=val_loader,\n",
    "    output_dir=\"./notebook_training_output\"\n",
    ")\n",
    "\n",
    "print(\"🚀 Starting training...\")\n",
    "history = trainer.train()\n",
    "print(\"✅ Training completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878348f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize training progress\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(history['train_loss'], label='Train Loss', color='blue')\n",
    "plt.plot(history['eval_loss'], label='Val Loss', color='red')\n",
    "plt.xlabel('Steps')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(history['train_accuracy'], label='Train Acc', color='blue')\n",
    "plt.plot(history['eval_accuracy'], label='Val Acc', color='red')\n",
    "plt.xlabel('Steps')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(history['learning_rate'], color='green')\n",
    "plt.xlabel('Steps')\n",
    "plt.ylabel('Learning Rate')\n",
    "plt.title('Learning Rate Schedule')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print final metrics\n",
    "print(f\"\\n📊 Final Training Results:\")\n",
    "print(f\"  Final train loss: {history['train_loss'][-1]:.4f}\")\n",
    "print(f\"  Final val loss: {history['eval_loss'][-1]:.4f}\")\n",
    "print(f\"  Final train accuracy: {history['train_accuracy'][-1]:.4f}\")\n",
    "print(f\"  Final val accuracy: {history['eval_accuracy'][-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bec4c62",
   "metadata": {},
   "source": [
    "## 7. Model Evaluation and Analysis\n",
    "\n",
    "Let's thoroughly evaluate our trained model and understand its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f29d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import itertools\n",
    "\n",
    "# Evaluate on validation set\n",
    "model.eval()\n",
    "val_predictions = []\n",
    "val_true_labels = []\n",
    "val_probabilities = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in val_loader:\n",
    "        outputs = model(batch['input_ids'], attention_mask=batch['attention_mask'])\n",
    "        predictions = torch.argmax(outputs.logits, dim=-1)\n",
    "        probabilities = torch.softmax(outputs.logits, dim=-1)\n",
    "        \n",
    "        val_predictions.extend(predictions.cpu().numpy())\n",
    "        val_true_labels.extend(batch['labels'].cpu().numpy())\n",
    "        val_probabilities.extend(probabilities.cpu().numpy())\n",
    "\n",
    "# Convert to numpy arrays\n",
    "val_predictions = np.array(val_predictions)\n",
    "val_true_labels = np.array(val_true_labels)\n",
    "val_probabilities = np.array(val_probabilities)\n",
    "\n",
    "# Class names for better visualization\n",
    "class_names = ['AT-rich', 'Moderate GC', 'GC-rich', 'Very GC-rich', 'TATA-box']\n",
    "\n",
    "# Classification report\n",
    "print(\"📋 Classification Report:\")\n",
    "print(classification_report(val_true_labels, val_predictions, target_names=class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e60104",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "cm = confusion_matrix(val_true_labels, val_predictions)\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(len(class_names))\n",
    "plt.xticks(tick_marks, class_names, rotation=45)\n",
    "plt.yticks(tick_marks, class_names)\n",
    "\n",
    "# Add text annotations\n",
    "thresh = cm.max() / 2.\n",
    "for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "    plt.text(j, i, format(cm[i, j], 'd'),\n",
    "             horizontalalignment=\"center\",\n",
    "             color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "\n",
    "# Class-wise accuracy\n",
    "plt.subplot(1, 3, 2)\n",
    "class_accuracy = cm.diagonal() / cm.sum(axis=1)\n",
    "plt.bar(range(len(class_names)), class_accuracy, color='lightgreen')\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Per-Class Accuracy')\n",
    "plt.xticks(range(len(class_names)), class_names, rotation=45)\n",
    "plt.ylim(0, 1)\n",
    "\n",
    "# Prediction confidence distribution\n",
    "plt.subplot(1, 3, 3)\n",
    "max_probs = np.max(val_probabilities, axis=1)\n",
    "plt.hist(max_probs, bins=20, alpha=0.7, color='orange')\n",
    "plt.xlabel('Prediction Confidence')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Prediction Confidence Distribution')\n",
    "plt.axvline(np.mean(max_probs), color='red', linestyle='--', label=f'Mean: {np.mean(max_probs):.3f}')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c35f03",
   "metadata": {},
   "source": [
    "## 8. Model Interpretation and Analysis\n",
    "\n",
    "Let's understand what our model has learned and how it makes predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f222393a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze model predictions on specific examples\n",
    "def analyze_prediction(sequence, model, tokenizer, class_names):\n",
    "    \"\"\"Analyze model prediction for a specific sequence.\"\"\"\n",
    "    # Tokenize\n",
    "    tokens = tokenizer.encode(sequence)\n",
    "    input_ids = torch.tensor([tokens])\n",
    "    \n",
    "    # Get model output\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids, output_attentions=True)\n",
    "        \n",
    "    # Get predictions and attention\n",
    "    logits = outputs.logits[0]\n",
    "    probabilities = torch.softmax(logits, dim=-1)\n",
    "    predicted_class = torch.argmax(logits).item()\n",
    "    \n",
    "    # Attention weights (average across heads and layers)\n",
    "    attention_weights = outputs.attentions[-1][0].mean(dim=0)  # Last layer, first sample, average heads\n",
    "    attention_weights = attention_weights.mean(dim=0)  # Average across query positions\n",
    "    \n",
    "    return predicted_class, probabilities.numpy(), attention_weights.numpy()\n",
    "\n",
    "# Test on some example sequences\n",
    "test_sequences = [\n",
    "    \"ATATATATATATATATATATATAT\",  # AT-rich\n",
    "    \"GCGCGCGCGCGCGCGCGCGCGCGC\",  # GC-rich\n",
    "    \"ATCGATCGATCGATCGATCGATCG\",  # Balanced\n",
    "    \"TATAAA\" + \"GCGCGC\" * 10,      # TATA box + GC-rich\n",
    "]\n",
    "\n",
    "print(\"🔍 Analyzing Example Predictions:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for i, seq in enumerate(test_sequences):\n",
    "    pred_class, probs, attention = analyze_prediction(seq, model, tokenizer, class_names)\n",
    "    \n",
    "    print(f\"\\nExample {i+1}: {seq[:30]}...\")\n",
    "    print(f\"  GC Content: {(seq.count('G') + seq.count('C')) / len(seq):.3f}\")\n",
    "    print(f\"  Predicted: {class_names[pred_class]} (confidence: {probs[pred_class]:.3f})\")\n",
    "    print(f\"  All probabilities: {dict(zip(class_names, probs))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e20878af",
   "metadata": {},
   "source": [
    "## 9. Practical Usage: Applying the Model\n",
    "\n",
    "Now let's see how to use our trained model for practical genomic sequence analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426d079d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sequence_type(sequence, model, tokenizer, class_names):\n",
    "    \"\"\"Predict the type of a genomic sequence.\"\"\"\n",
    "    # Tokenize and prepare input\n",
    "    tokens = tokenizer.encode(sequence)\n",
    "    input_ids = torch.tensor([tokens])\n",
    "    \n",
    "    # Get prediction\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids)\n",
    "        probabilities = torch.softmax(outputs.logits, dim=-1)[0]\n",
    "        predicted_class = torch.argmax(probabilities).item()\n",
    "    \n",
    "    return predicted_class, probabilities.numpy()\n",
    "\n",
    "def batch_predict(sequences, model, tokenizer, class_names, batch_size=32):\n",
    "    \"\"\"Predict types for multiple sequences efficiently.\"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for i in range(0, len(sequences), batch_size):\n",
    "        batch_seqs = sequences[i:i+batch_size]\n",
    "        batch_tokens = [tokenizer.encode(seq) for seq in batch_seqs]\n",
    "        \n",
    "        # Pad sequences to same length\n",
    "        max_len = max(len(tokens) for tokens in batch_tokens)\n",
    "        padded_tokens = []\n",
    "        attention_masks = []\n",
    "        \n",
    "        for tokens in batch_tokens:\n",
    "            padding_length = max_len - len(tokens)\n",
    "            padded = tokens + [tokenizer.pad_token_id] * padding_length\n",
    "            mask = [1] * len(tokens) + [0] * padding_length\n",
    "            \n",
    "            padded_tokens.append(padded)\n",
    "            attention_masks.append(mask)\n",
    "        \n",
    "        # Convert to tensors\n",
    "        input_ids = torch.tensor(padded_tokens)\n",
    "        attention_mask = torch.tensor(attention_masks)\n",
    "        \n",
    "        # Get predictions\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            probabilities = torch.softmax(outputs.logits, dim=-1)\n",
    "            predictions = torch.argmax(probabilities, dim=-1)\n",
    "        \n",
    "        # Store results\n",
    "        for j, (seq, pred, probs) in enumerate(zip(batch_seqs, predictions, probabilities)):\n",
    "            results.append({\n",
    "                'sequence': seq,\n",
    "                'predicted_class': class_names[pred.item()],\n",
    "                'confidence': probs[pred].item(),\n",
    "                'all_probabilities': {name: prob.item() for name, prob in zip(class_names, probs)}\n",
    "            })\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Test the prediction functions\n",
    "test_sequences = [\n",
    "    \"AAAAAAAAAAAAAAAAAAAAAAAAAAAA\",  # Very AT-rich\n",
    "    \"GGGGGGGGGGGGGGGGGGGGGGGGGGGG\",  # Very GC-rich\n",
    "    \"ATCGATCGATCGATCGATCGATCGATCG\",  # Balanced\n",
    "    \"TATAAAGCGCGCGCGCGCGCGCGCGCGC\",  # TATA + GC-rich\n",
    "    \"CGATCGATCGATCGATCGATCGATCGAT\",  # Random-looking\n",
    "]\n",
    "\n",
    "print(\"🎯 Testing Prediction Functions:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for i, seq in enumerate(test_sequences):\n",
    "    pred_class, probs = predict_sequence_type(seq, model, tokenizer, class_names)\n",
    "    print(f\"Sequence {i+1}: {seq[:20]}...\")\n",
    "    print(f\"  Prediction: {class_names[pred_class]} ({probs[pred_class]:.3f} confidence)\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0002a7ee",
   "metadata": {},
   "source": [
    "## 10. Saving and Loading Models\n",
    "\n",
    "Learn how to save your trained models and load them for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f304b989",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "model_save_path = \"./my_first_hyena_glt_model\"\n",
    "os.makedirs(model_save_path, exist_ok=True)\n",
    "\n",
    "# Save model and tokenizer\n",
    "model.save_pretrained(model_save_path)\n",
    "tokenizer.save_pretrained(model_save_path)\n",
    "\n",
    "# Save additional metadata\n",
    "import json\n",
    "metadata = {\n",
    "    \"model_type\": \"hyena-glt\",\n",
    "    \"task\": \"dna_classification\",\n",
    "    \"classes\": class_names,\n",
    "    \"training_samples\": len(train_dataset),\n",
    "    \"validation_accuracy\": float(history['eval_accuracy'][-1]),\n",
    "    \"sequence_type\": \"dna\",\n",
    "    \"max_length\": config.max_length\n",
    "}\n",
    "\n",
    "with open(f\"{model_save_path}/metadata.json\", 'w') as f:\n",
    "    json.dump(metadata, f, indent=2)\n",
    "\n",
    "print(f\"✅ Model saved to: {model_save_path}\")\n",
    "\n",
    "# Demonstrate loading the model\n",
    "print(\"\\n🔄 Loading model from disk...\")\n",
    "\n",
    "# Load model and tokenizer\n",
    "loaded_model = HyenaGLT.from_pretrained(model_save_path)\n",
    "loaded_tokenizer = DNATokenizer.from_pretrained(model_save_path)\n",
    "\n",
    "# Load metadata\n",
    "with open(f\"{model_save_path}/metadata.json\", 'r') as f:\n",
    "    loaded_metadata = json.load(f)\n",
    "\n",
    "print(f\"📋 Loaded model metadata:\")\n",
    "for key, value in loaded_metadata.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "# Test that loaded model works\n",
    "test_seq = \"ATCGATCGATCGATCGATCGATCG\"\n",
    "original_pred, original_probs = predict_sequence_type(test_seq, model, tokenizer, class_names)\n",
    "loaded_pred, loaded_probs = predict_sequence_type(test_seq, loaded_model, loaded_tokenizer, class_names)\n",
    "\n",
    "print(f\"\\n🧪 Verification Test:\")\n",
    "print(f\"  Original model prediction: {class_names[original_pred]} ({original_probs[original_pred]:.4f})\")\n",
    "print(f\"  Loaded model prediction: {class_names[loaded_pred]} ({loaded_probs[loaded_pred]:.4f})\")\n",
    "print(f\"  Predictions match: {original_pred == loaded_pred}\")\n",
    "print(f\"  Probabilities match: {np.allclose(original_probs, loaded_probs, atol=1e-6)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ee8a57",
   "metadata": {},
   "source": [
    "## 6. Training Your First Model\n",
    "\n",
    "Now let's train a Hyena-GLT model on our synthetic data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c893c958",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train/validation\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "print(f\"Training samples: {len(train_dataset)}\")\n",
    "print(f\"Validation samples: {len(val_dataset)}\")\n",
    "\n",
    "# Training configuration\n",
    "training_config = TrainingConfig(\n",
    "    learning_rate=1e-4,\n",
    "    batch_size=8,\n",
    "    num_epochs=3,  # Small number for demo\n",
    "    warmup_steps=100,\n",
    "    weight_decay=0.01,\n",
    "    gradient_clipping=1.0,\n",
    "    save_steps=100,\n",
    "    eval_steps=50,\n",
    "    logging_steps=25\n",
    ")\n",
    "\n",
    "print(f\"\\nTraining configuration:\")\n",
    "print(f\"  Learning rate: {training_config.learning_rate}\")\n",
    "print(f\"  Batch size: {training_config.batch_size}\")\n",
    "print(f\"  Epochs: {training_config.num_epochs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a29832b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize trainer\n",
    "trainer = HyenaGLTTrainer(\n",
    "    model=model,\n",
    "    config=training_config,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    output_dir=\"./demo_output\"\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "print(\"🚀 Starting training...\")\n",
    "training_history = trainer.train()\n",
    "\n",
    "print(\"\\n✅ Training completed!\")\n",
    "print(f\"Final training loss: {training_history['train_loss'][-1]:.4f}\")\n",
    "print(f\"Final validation loss: {training_history['val_loss'][-1]:.4f}\")\n",
    "print(f\"Final validation accuracy: {training_history['val_accuracy'][-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a9cbfa",
   "metadata": {},
   "source": [
    "## 7. Model Evaluation\n",
    "\n",
    "Let's evaluate our trained model using comprehensive genomic metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc57a09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on validation set\n",
    "model.eval()\n",
    "all_predictions = []\n",
    "all_labels = []\n",
    "all_probabilities = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in val_loader:\n",
    "        outputs = model(\n",
    "            input_ids=batch['input_ids'],\n",
    "            attention_mask=batch['attention_mask']\n",
    "        )\n",
    "        \n",
    "        predictions = torch.argmax(outputs.logits, dim=-1)\n",
    "        probabilities = torch.softmax(outputs.logits, dim=-1)\n",
    "        \n",
    "        all_predictions.extend(predictions.cpu().numpy())\n",
    "        all_labels.extend(batch['labels'].cpu().numpy())\n",
    "        all_probabilities.extend(probabilities.cpu().numpy())\n",
    "\n",
    "all_predictions = np.array(all_predictions)\n",
    "all_labels = np.array(all_labels)\n",
    "all_probabilities = np.array(all_probabilities)\n",
    "\n",
    "print(f\"Evaluation completed on {len(all_predictions)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0870a22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate metrics\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix\n",
    "\n",
    "accuracy = accuracy_score(all_labels, all_predictions)\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(all_labels, all_predictions, average='weighted')\n",
    "\n",
    "print(\"📊 Evaluation Metrics:\")\n",
    "print(f\"  Accuracy: {accuracy:.4f}\")\n",
    "print(f\"  Precision: {precision:.4f}\")\n",
    "print(f\"  Recall: {recall:.4f}\")\n",
    "print(f\"  F1-score: {f1:.4f}\")\n",
    "\n",
    "# Per-class metrics\n",
    "class_names = ['AT-rich', 'Moderate GC', 'GC-rich', 'Very GC-rich', 'Promoter']\n",
    "precision_per_class, recall_per_class, f1_per_class, support = precision_recall_fscore_support(\n",
    "    all_labels, all_predictions, average=None\n",
    ")\n",
    "\n",
    "print(\"\\n📈 Per-class Performance:\")\n",
    "for i, class_name in enumerate(class_names):\n",
    "    if i < len(precision_per_class):\n",
    "        print(f\"  {class_name}:\")\n",
    "        print(f\"    Precision: {precision_per_class[i]:.4f}\")\n",
    "        print(f\"    Recall: {recall_per_class[i]:.4f}\")\n",
    "        print(f\"    F1: {f1_per_class[i]:.4f}\")\n",
    "        print(f\"    Support: {support[i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c477f5e3",
   "metadata": {},
   "source": [
    "## 8. Visualization and Analysis\n",
    "\n",
    "Let's create visualizations to better understand our model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2591c19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training curves\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Training and validation loss\n",
    "axes[0, 0].plot(training_history['train_loss'], label='Training Loss', color='blue')\n",
    "axes[0, 0].plot(training_history['val_loss'], label='Validation Loss', color='red')\n",
    "axes[0, 0].set_title('Training and Validation Loss')\n",
    "axes[0, 0].set_xlabel('Step')\n",
    "axes[0, 0].set_ylabel('Loss')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True)\n",
    "\n",
    "# Validation accuracy\n",
    "axes[0, 1].plot(training_history['val_accuracy'], label='Validation Accuracy', color='green')\n",
    "axes[0, 1].set_title('Validation Accuracy')\n",
    "axes[0, 1].set_xlabel('Step')\n",
    "axes[0, 1].set_ylabel('Accuracy')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True)\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(all_labels, all_predictions)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[1, 0])\n",
    "axes[1, 0].set_title('Confusion Matrix')\n",
    "axes[1, 0].set_xlabel('Predicted')\n",
    "axes[1, 0].set_ylabel('Actual')\n",
    "\n",
    "# Class distribution\n",
    "unique_labels, counts = np.unique(all_labels, return_counts=True)\n",
    "axes[1, 1].bar(class_names[:len(unique_labels)], counts, color='skyblue')\n",
    "axes[1, 1].set_title('Class Distribution in Validation Set')\n",
    "axes[1, 1].set_xlabel('Class')\n",
    "axes[1, 1].set_ylabel('Count')\n",
    "axes[1, 1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bbce6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze model predictions\n",
    "# Find examples where the model is most confident\n",
    "max_probs = np.max(all_probabilities, axis=1)\n",
    "confidence_threshold = 0.9\n",
    "high_confidence_mask = max_probs > confidence_threshold\n",
    "\n",
    "print(f\"High confidence predictions (>{confidence_threshold}): {high_confidence_mask.sum()}\")\n",
    "print(f\"Accuracy on high confidence predictions: {accuracy_score(all_labels[high_confidence_mask], all_predictions[high_confidence_mask]):.4f}\")\n",
    "\n",
    "# Find examples where the model made mistakes\n",
    "mistakes = all_predictions != all_labels\n",
    "print(f\"\\nNumber of mistakes: {mistakes.sum()}\")\n",
    "print(f\"Mistake rate: {mistakes.mean():.4f}\")\n",
    "\n",
    "# Analyze mistakes by class\n",
    "print(\"\\nMistakes by true class:\")\n",
    "for i, class_name in enumerate(class_names):\n",
    "    class_mask = all_labels == i\n",
    "    if class_mask.sum() > 0:\n",
    "        class_mistakes = mistakes[class_mask].sum()\n",
    "        class_total = class_mask.sum()\n",
    "        mistake_rate = class_mistakes / class_total\n",
    "        print(f\"  {class_name}: {class_mistakes}/{class_total} ({mistake_rate:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca57eb33",
   "metadata": {},
   "source": [
    "## 9. Model Interpretation\n",
    "\n",
    "Let's explore what the model has learned by examining attention patterns and feature importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3138834",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze model's internal representations\n",
    "model.eval()\n",
    "\n",
    "# Get a sample for analysis\n",
    "sample_idx = 0\n",
    "sample_data = val_dataset[sample_idx]\n",
    "sample_sequence = sequences[val_dataset.indices[sample_idx]]\n",
    "sample_label = sample_data['labels'].item()\n",
    "\n",
    "print(f\"Analyzing sample {sample_idx}:\")\n",
    "print(f\"Sequence length: {len(sample_sequence)}\")\n",
    "print(f\"True label: {class_names[sample_label]}\")\n",
    "print(f\"Sequence preview: {sample_sequence[:50]}...\")\n",
    "\n",
    "# Forward pass with attention\n",
    "with torch.no_grad():\n",
    "    input_ids = sample_data['input_ids'].unsqueeze(0)\n",
    "    attention_mask = sample_data['attention_mask'].unsqueeze(0)\n",
    "    \n",
    "    outputs = model(\n",
    "        input_ids=input_ids,\n",
    "        attention_mask=attention_mask,\n",
    "        output_attentions=True\n",
    "    )\n",
    "    \n",
    "    prediction = torch.argmax(outputs.logits, dim=-1).item()\n",
    "    probabilities = torch.softmax(outputs.logits, dim=-1).squeeze().cpu().numpy()\n",
    "    \n",
    "print(f\"\\nPredicted label: {class_names[prediction]}\")\n",
    "print(f\"Prediction confidence: {probabilities[prediction]:.4f}\")\n",
    "\n",
    "print(\"\\nClass probabilities:\")\n",
    "for i, (class_name, prob) in enumerate(zip(class_names, probabilities)):\n",
    "    print(f\"  {class_name}: {prob:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c006941",
   "metadata": {},
   "source": [
    "## 10. Practical Applications\n",
    "\n",
    "Let's demonstrate how to apply the trained model to new genomic sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4477d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sequence_type(sequence, model, tokenizer, class_names):\n",
    "    \"\"\"Predict the type of a genomic sequence.\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Tokenize\n",
    "    tokens = tokenizer.encode(sequence)\n",
    "    input_ids = torch.tensor(tokens).unsqueeze(0)\n",
    "    \n",
    "    # Create attention mask\n",
    "    attention_mask = torch.ones_like(input_ids)\n",
    "    \n",
    "    # Predict\n",
    "    with torch.no_grad():\n",
    "        outputs = model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask\n",
    "        )\n",
    "        \n",
    "        probabilities = torch.softmax(outputs.logits, dim=-1).squeeze().cpu().numpy()\n",
    "        prediction = np.argmax(probabilities)\n",
    "    \n",
    "    return prediction, probabilities\n",
    "\n",
    "# Test on new sequences\n",
    "test_sequences = [\n",
    "    \"ATATAAATCGATCGTAGCTAGC\",  # Contains TATA box\n",
    "    \"GCGCGCGCGCGCGCGCGCGC\",   # Very GC-rich\n",
    "    \"AAAAAATTTTTTAAAAATTTTT\", # Very AT-rich\n",
    "    \"ATCGATCGATCGATCGATCG\",   # Balanced\n",
    "]\n",
    "\n",
    "print(\"🔬 Testing on new sequences:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for i, seq in enumerate(test_sequences):\n",
    "    prediction, probabilities = predict_sequence_type(\n",
    "        seq, model, tokenizer, class_names\n",
    "    )\n",
    "    \n",
    "    gc_content = (seq.count('G') + seq.count('C')) / len(seq)\n",
    "    \n",
    "    print(f\"\\nSequence {i+1}: {seq}\")\n",
    "    print(f\"GC content: {gc_content:.2f}\")\n",
    "    print(f\"Predicted type: {class_names[prediction]}\")\n",
    "    print(f\"Confidence: {probabilities[prediction]:.4f}\")\n",
    "    \n",
    "    # Show top 2 predictions\n",
    "    top_indices = np.argsort(probabilities)[::-1][:2]\n",
    "    print(\"Top predictions:\")\n",
    "    for idx in top_indices:\n",
    "        print(f\"  {class_names[idx]}: {probabilities[idx]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceae6632",
   "metadata": {},
   "source": [
    "## 11. Model Saving and Loading\n",
    "\n",
    "Learn how to save and load your trained models for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e03ebff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model and configuration\n",
    "save_dir = Path(\"./saved_models/dna_classifier\")\n",
    "save_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save model state\n",
    "torch.save(model.state_dict(), save_dir / \"model.pt\")\n",
    "\n",
    "# Save configuration\n",
    "config.save_json(save_dir / \"config.json\")\n",
    "\n",
    "# Save tokenizer vocabulary\n",
    "import json\n",
    "with open(save_dir / \"tokenizer_vocab.json\", 'w') as f:\n",
    "    json.dump(tokenizer.vocab, f)\n",
    "\n",
    "print(f\"✅ Model saved to: {save_dir}\")\n",
    "\n",
    "# Demonstrate loading\n",
    "print(\"\\n🔄 Loading model...\")\n",
    "\n",
    "# Load configuration\n",
    "loaded_config = HyenaGLTConfig.from_json(save_dir / \"config.json\")\n",
    "\n",
    "# Create new model\n",
    "loaded_model = HyenaGLT(loaded_config)\n",
    "\n",
    "# Load weights\n",
    "loaded_model.load_state_dict(torch.load(save_dir / \"model.pt\"))\n",
    "\n",
    "print(\"✅ Model loaded successfully!\")\n",
    "\n",
    "# Verify loaded model works\n",
    "test_seq = \"ATCGATCGTAGCTAGC\"\n",
    "pred1, prob1 = predict_sequence_type(test_seq, model, tokenizer, class_names)\n",
    "pred2, prob2 = predict_sequence_type(test_seq, loaded_model, tokenizer, class_names)\n",
    "\n",
    "print(f\"\\nVerification:\")\n",
    "print(f\"Original model prediction: {class_names[pred1]} ({prob1[pred1]:.4f})\")\n",
    "print(f\"Loaded model prediction: {class_names[pred2]} ({prob2[pred2]:.4f})\")\n",
    "print(f\"Predictions match: {pred1 == pred2}\")\n",
    "print(f\"Probabilities match: {np.allclose(prob1, prob2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d54b266f",
   "metadata": {},
   "source": [
    "## 12. Next Steps and Advanced Topics\n",
    "\n",
    "Congratulations! You've successfully trained and evaluated your first Hyena-GLT model. Here are some next steps to explore:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b1896b",
   "metadata": {},
   "source": [
    "### 🎯 Immediate Next Steps\n",
    "\n",
    "1. **Try different genomic tasks**:\n",
    "   - RNA secondary structure prediction\n",
    "   - Protein function classification\n",
    "   - Variant effect prediction\n",
    "\n",
    "2. **Experiment with model architectures**:\n",
    "   - Different hidden sizes and layer counts\n",
    "   - Various Hyena orders\n",
    "   - Custom positional encodings\n",
    "\n",
    "3. **Improve data quality**:\n",
    "   - Use real genomic datasets\n",
    "   - Implement data augmentation\n",
    "   - Balance class distributions\n",
    "\n",
    "### 🚀 Advanced Applications\n",
    "\n",
    "4. **Multi-task learning**: Train on multiple genomic tasks simultaneously\n",
    "5. **Transfer learning**: Fine-tune pre-trained models on specific tasks\n",
    "6. **Model optimization**: Quantization, pruning, and knowledge distillation\n",
    "7. **Distributed training**: Scale to larger datasets and models\n",
    "\n",
    "### 📚 Additional Resources\n",
    "\n",
    "- Check out other notebooks in this directory\n",
    "- Read the comprehensive documentation\n",
    "- Explore the example scripts\n",
    "- Join the community discussions\n",
    "\n",
    "### 🛠️ Useful Functions for Your Projects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e84f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility functions you can use in your own projects\n",
    "\n",
    "def quick_train(sequences, labels, task_type='classification', epochs=5):\n",
    "    \"\"\"Quickly train a model on your data.\"\"\"\n",
    "    # Determine sequence type\n",
    "    sample_seq = sequences[0]\n",
    "    if set(sample_seq.upper()).issubset({'A', 'T', 'C', 'G'}):\n",
    "        sequence_type = 'dna'\n",
    "        tokenizer = DNATokenizer()\n",
    "    elif set(sample_seq.upper()).issubset({'A', 'U', 'C', 'G'}):\n",
    "        sequence_type = 'rna'\n",
    "        tokenizer = RNATokenizer()\n",
    "    else:\n",
    "        sequence_type = 'protein'\n",
    "        tokenizer = ProteinTokenizer()\n",
    "    \n",
    "    # Create config\n",
    "    if task_type == 'classification':\n",
    "        num_classes = len(set(labels))\n",
    "        if sequence_type == 'dna':\n",
    "            config = HyenaGLTConfig.for_dna_classification(num_classes=num_classes)\n",
    "        elif sequence_type == 'rna':\n",
    "            config = HyenaGLTConfig.for_rna_structure()\n",
    "        else:\n",
    "            config = HyenaGLTConfig.for_protein_function(num_functions=num_classes)\n",
    "    \n",
    "    # Create dataset and model\n",
    "    dataset = GenomicDataset(sequences, labels, tokenizer, config.max_length)\n",
    "    model = HyenaGLT(config)\n",
    "    \n",
    "    # Quick training setup\n",
    "    train_loader = DataLoader(dataset, batch_size=8, shuffle=True)\n",
    "    training_config = TrainingConfig(num_epochs=epochs, learning_rate=1e-4)\n",
    "    \n",
    "    trainer = HyenaGLTTrainer(\n",
    "        model=model,\n",
    "        config=training_config,\n",
    "        train_loader=train_loader,\n",
    "        output_dir=\"./quick_train_output\"\n",
    "    )\n",
    "    \n",
    "    # Train\n",
    "    history = trainer.train()\n",
    "    \n",
    "    return model, tokenizer, config, history\n",
    "\n",
    "def analyze_sequences(sequences, model, tokenizer, class_names):\n",
    "    \"\"\"Analyze a list of sequences with a trained model.\"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for seq in sequences:\n",
    "        pred, probs = predict_sequence_type(seq, model, tokenizer, class_names)\n",
    "        \n",
    "        result = {\n",
    "            'sequence': seq,\n",
    "            'length': len(seq),\n",
    "            'gc_content': (seq.count('G') + seq.count('C')) / len(seq),\n",
    "            'predicted_class': class_names[pred],\n",
    "            'confidence': probs[pred],\n",
    "            'all_probabilities': probs\n",
    "        }\n",
    "        results.append(result)\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "print(\"🛠️ Utility functions defined!\")\n",
    "print(\"You can now use:\")\n",
    "print(\"  - quick_train(sequences, labels) for rapid prototyping\")\n",
    "print(\"  - analyze_sequences(sequences, model, tokenizer, class_names) for batch analysis\")\n",
    "print(\"  - predict_sequence_type(sequence, model, tokenizer, class_names) for single predictions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da63403f",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, you learned:\n",
    "\n",
    "✅ **Hyena-GLT Basics**: Understanding the architecture and configuration system  \n",
    "✅ **Data Processing**: Tokenizing genomic sequences and creating datasets  \n",
    "✅ **Model Training**: Training a model on synthetic genomic data  \n",
    "✅ **Evaluation**: Comprehensive performance analysis and visualization  \n",
    "✅ **Model Interpretation**: Understanding what the model learns  \n",
    "✅ **Practical Usage**: Applying trained models to new sequences  \n",
    "✅ **Model Persistence**: Saving and loading models  \n",
    "✅ **Utility Functions**: Reusable code for your projects  \n",
    "\n",
    "**What's Next?**\n",
    "\n",
    "- Explore other notebooks for specific genomic tasks\n",
    "- Try training on real genomic datasets\n",
    "- Experiment with different model architectures\n",
    "- Implement custom genomic tasks\n",
    "\n",
    "Happy genomic modeling with Hyena-GLT! 🧬🚀"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
